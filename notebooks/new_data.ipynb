{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST MODEL ON UNKNOWN DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and spotipy authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import spotipy.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication details\n",
    "my_username = \"oso41\"\n",
    "chosen_scope = \"user-library-read playlist-modify-private\"\n",
    "my_client_id = \"\"\n",
    "my_client_secret = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token creation\n",
    "token = util.prompt_for_user_token(username=my_username,\n",
    "                                   scope=chosen_scope,\n",
    "                                   client_id=my_client_id,\n",
    "                                   client_secret=my_client_secret,\n",
    "                                   redirect_uri=\"http://127.0.0.1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotipy object\n",
    "sp = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously trained classification model\n",
    "filename = 'final_model.sav'\n",
    "rfc = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to retrieve track features from a playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks(playlist_id, playlist_length):\n",
    "    '''Gets the main information for all tracks in a playlist\n",
    "    \n",
    "    Input:\n",
    "    --------------\n",
    "    playlist_id (str): playlist id retrieved manually from spotify\n",
    "    playlist_length (int): number of tracks in the playlist\n",
    "    \n",
    "    Returns:\n",
    "    --------------\n",
    "    df (df): dataframe with tracks information (artist_name, track_name, track_id and popularity)\n",
    "    '''\n",
    "        \n",
    "    artist_name = []\n",
    "    track_name = []\n",
    "    popularity = []\n",
    "    track_id = []\n",
    "    \n",
    "    for i in range(0,playlist_length,100):\n",
    "        results = sp.user_playlist_tracks(my_username,playlist_id=playlist_id,limit=100, offset=i)\n",
    "        for i, t in enumerate(results['items']):\n",
    "            artist_name.append(t['track']['artists'][0]['name'])\n",
    "            track_name.append(t['track']['name'])\n",
    "            track_id.append(t['track']['id'])\n",
    "            popularity.append(t['track']['popularity'])\n",
    "    \n",
    "    df = pd.DataFrame([artist_name,track_name,track_id,popularity]).transpose()\n",
    "    df.columns = ['artist_name','track_name','track_id','popularity']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tracks_df(df):\n",
    "    '''Cleans dataframe\n",
    "    \n",
    "    Input:\n",
    "    --------------\n",
    "    df (df): dataframe with tracks information\n",
    "    \n",
    "    Returns:\n",
    "    --------------\n",
    "    df (df): cleaned dataframe\n",
    "    '''\n",
    "    \n",
    "    # Some songs appear twice (this is not avoided with unique uri), so they are deleted making sure \n",
    "    # that the combination of 'artist_name' and 'track_name' just appears once\n",
    "    df = df.drop_duplicates(subset=['artist_name','track_name'])\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    '''Gets the features for all tracks in a dataframe\n",
    "    \n",
    "    Input:\n",
    "    --------------\n",
    "    df (df): dataframe with tracks information\n",
    "    \n",
    "    Returns:\n",
    "    --------------\n",
    "    df (df): dataframe with features for each track\n",
    "    '''\n",
    "    \n",
    "    # Create empty list to store songs features\n",
    "    rows = []\n",
    "\n",
    "    # Retrieve audio features for every track\n",
    "    for i in range(0,len(df['track_id']),50):\n",
    "        feature_results = sp.audio_features(df['track_id'][i:i+50])\n",
    "        for features in feature_results:\n",
    "            rows.append(features)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(rows,orient='columns')\n",
    "    \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_features_df(df):\n",
    "    '''Cleans dataframe containig tracks features\n",
    "    \n",
    "    Input:\n",
    "    --------------\n",
    "    df (df): dataframe with tracks features\n",
    "    \n",
    "    Returns:\n",
    "    --------------\n",
    "    df (df): cleaned dataframe\n",
    "    '''\n",
    "    \n",
    "    # Drop columns containing useless information\n",
    "    df = df.drop(['analysis_url','track_href','type','uri'],axis=1)\n",
    "    # Change 'id' name to 'track_id' in order to match with previous dataframe (prepare for merging)\n",
    "    df = df.rename(columns={'id':'track_id'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df1,df2):\n",
    "    '''Merges two dataframes with tracks information and tracks features\n",
    "    \n",
    "    Input:\n",
    "    --------------\n",
    "    df1 (df): dataframe with tracks information\n",
    "    df2 (df): dataframe with features for each track\n",
    "    \n",
    "    Returns:\n",
    "    --------------\n",
    "    df (df): dataframe with tracks information and features for each track\n",
    "    '''\n",
    "    \n",
    "    df = pd.merge(df1,df2,on='track_id',how='inner')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(df):\n",
    "    '''Returns a dataframe with scaled features.\n",
    "       \n",
    "    Input:\n",
    "    --------------\n",
    "    df (df): dataframe without all features scaled\n",
    "    \n",
    "    Returns:\n",
    "    --------------\n",
    "    df (df): dataframe with all features scaled\n",
    "    '''\n",
    "    \n",
    "    columns_to_normalize = ['popularity','duration_ms','loudness','tempo','key','time_signature']\n",
    "    \n",
    "    for col in columns_to_normalize:\n",
    "        x = df[col].values.reshape(-1,1)\n",
    "        minmaxscaler = MinMaxScaler()\n",
    "        x_scaled = minmaxscaler.fit_transform(x)\n",
    "        df[col] = pd.DataFrame(x_scaled)\n",
    "    \n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(playlist_id, playlist_length):\n",
    "    '''Applies the functions get_tracks, clean_tracks, get_features, clean_features, merge and scaling to a playlist\n",
    "    \n",
    "    Input:\n",
    "    --------------\n",
    "    playlist_id (str): playlist id retrieved manually from spotify\n",
    "    playlist_length (int): number of tracks in the playlist\n",
    "    \n",
    "    Returns:\n",
    "    --------------\n",
    "    df (df): dataframe with tracks information and features for each track\n",
    "    '''\n",
    "    \n",
    "    df_t = get_tracks(playlist_id,playlist_length)\n",
    "    df_t = clean_tracks_df(df_t)\n",
    "    df_f = get_features(df_t)\n",
    "    df_f = clean_features_df(df_f)\n",
    "    df = merge(df_t,df_f)\n",
    "    df = scaling(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to predict and create new playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, df):\n",
    "    '''Predicts the likeableness for songs contained in a dataframe\n",
    "    \n",
    "    Input:\n",
    "    --------------\n",
    "    model (sklearn object): Previously trained classification model to be used for predictions \n",
    "    df (df): Dataframe with tracks information and features for each track\n",
    "    \n",
    "    Returns:\n",
    "    --------------\n",
    "    df (df): dataframe with added column for predictions\n",
    "    '''\n",
    "    \n",
    "    X = df[['popularity', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
    "       'speechiness', 'tempo', 'time_signature', 'valence']]\n",
    "    \n",
    "    df['like'] = model.predict(X)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_playlists(df,my_username):\n",
    "    '''Creates two playlists in Spotify for liked and disliked songs\n",
    "    \n",
    "    Input:\n",
    "    --------------\n",
    "    df (df): Dataframe with tracks information, features and predictions\n",
    "    my_username (str): The user name for which the playlist will be created\n",
    "    '''\n",
    "    \n",
    "    good_pl = sp.user_playlist_create(user=my_username,name='Spotipie',public=False)\n",
    "    bad_pl = sp.user_playlist_create(user=my_username,name='Spotimal',public=False)\n",
    "    \n",
    "    good_tracks = [f'spotify:track:{track_id}' for track_id in df[df['like']==1]['track_id']]\n",
    "    bad_tracks = [f'spotify:track:{track_id}' for track_id in df[df['like']==0]['track_id']]\n",
    "    \n",
    "    for i in range(0,len(good_tracks),100):\n",
    "        sp.user_playlist_add_tracks(my_username,good_pl['uri'].split(':')[-1],good_tracks[i:i+100])\n",
    "    \n",
    "    for i in range(0,len(bad_tracks),100):\n",
    "        sp.user_playlist_add_tracks(my_username,bad_pl['uri'].split(':')[-1],bad_tracks[i:i+100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTIONS\n",
    "\n",
    "# Get dataframe for a specific playlist ready for predictions\n",
    "\n",
    "unk_df = pipeline('37i9dQZF1DXasneILDRM7B',50)\n",
    "\n",
    "# Predict\n",
    "\n",
    "unk_df = predict(rfc, unk_df)\n",
    "\n",
    "# Create playlists from predictions\n",
    "\n",
    "create_playlists(unk_df, my_username)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
